{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'flowtron'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/flowtron.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Research\\nvidia_flowtron\\flowtron\n",
      "g:\\Research\\nvidia_flowtron\\flowtron\\tacotron2\n"
     ]
    }
   ],
   "source": [
    "%cd flowtron\n",
    "!git submodule update --init\n",
    "%cd tacotron2\n",
    "!git submodule update --init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "11.8\n",
      "3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# print torch version for reference\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "# print torch cuda version for reference\n",
    "print(torch.version.cuda)\n",
    "# print python version for reference\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive G is Games\n",
      " Volume Serial Number is F002-617B\n",
      "\n",
      " Directory of g:\\Research\\nvidia_flowtron\n",
      "\n",
      "06/01/2024  01:07    <DIR>          .\n",
      "06/01/2024  00:53    <DIR>          ..\n",
      "06/01/2024  01:06    <DIR>          flowtron\n",
      "06/01/2024  01:04             1.883 flowtron.ipynb\n",
      "06/01/2024  01:07       245.121.888 flowtron.pt\n",
      "               2 File(s)    245.123.771 bytes\n",
      "               3 Dir(s)  248.566.210.560 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting resampy==0.3.1\n",
      "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/3.1 MB 991.0 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.4/3.1 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.5/3.1 MB 10.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.9/3.1 MB 15.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.1/3.1 MB 16.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from resampy==0.3.1) (1.19.2)\n",
      "Requirement already satisfied: numba>=0.47 in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from resampy==0.3.1) (0.48.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from numba>=0.47->resampy==0.3.1) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from numba>=0.47->resampy==0.3.1) (68.2.2)\n",
      "Installing collected packages: resampy\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.4.2\n",
      "    Uninstalling resampy-0.4.2:\n",
      "      Successfully uninstalled resampy-0.4.2\n",
      "Successfully installed resampy-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install resampy==0.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/NVIDIA/flowtron/issues/155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba==0.48\n",
      "  Downloading numba-0.48.0-1-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.5/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.0/2.1 MB 9.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.2/2.1 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 7.9 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0 (from numba==0.48)\n",
      "  Downloading llvmlite-0.31.0-cp38-cp38-win_amd64.whl (13.6 MB)\n",
      "     ---------------------------------------- 0.0/13.6 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/13.6 MB 33.4 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 1.0/13.6 MB 33.4 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 1.6/13.6 MB 11.7 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/13.6 MB 13.3 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 2.4/13.6 MB 10.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/13.6 MB 12.5 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.2/13.6 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.2/13.6 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/13.6 MB 4.2 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.2/13.6 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.4/13.6 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.3/13.6 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.5/13.6 MB 5.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.3/13.6 MB 5.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.3/13.6 MB 5.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 9.1/13.6 MB 6.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.9/13.6 MB 6.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.3/13.6 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.5/13.6 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.9/13.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 12.6/13.6 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.8/13.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 13.6/13.6 MB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from numba==0.48) (1.19.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages (from numba==0.48) (68.2.2)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.39.1\n",
      "    Uninstalling llvmlite-0.39.1:\n",
      "      Successfully uninstalled llvmlite-0.39.1\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.56.4\n",
      "    Uninstalling numba-0.56.4:\n",
      "      Successfully uninstalled numba-0.56.4\n",
      "Successfully installed llvmlite-0.31.0 numba-0.48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "resampy 0.4.2 requires numba>=0.53, but you have numba 0.48.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numba==0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/librosa/librosa/issues/1160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# %cd flowtron\n",
    "!python train.py -c pre-trained.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Research\\nvidia_flowtron\\flowtron\n"
     ]
    }
   ],
   "source": [
    "%cd flowtron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict Flowtron(\n",
      "  (speaker_embedding): Embedding(2311, 128)\n",
      "  (embedding): Embedding(185, 512)\n",
      "  (flows): ModuleList(\n",
      "    (0): AR_Step(\n",
      "      (conv): Conv1d(1024, 160, kernel_size=(1,), stride=(1,))\n",
      "      (lstm): LSTM(1664, 1024, num_layers=2)\n",
      "      (attention_lstm): LSTM(80, 1024)\n",
      "      (attention_layer): Attention(\n",
      "        (softmax): Softmax(dim=2)\n",
      "        (query): LinearNorm(\n",
      "          (linear_layer): Linear(in_features=1024, out_features=640, bias=False)\n",
      "        )\n",
      "        (key): LinearNorm(\n",
      "          (linear_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "        )\n",
      "        (value): LinearNorm(\n",
      "          (linear_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "        )\n",
      "        (v): LinearNorm(\n",
      "          (linear_layer): Linear(in_features=640, out_features=1, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (dense_layer): DenseLayer(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x LinearNorm(\n",
      "            (linear_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AR_Back_Step(\n",
      "      (ar_step): AR_Step(\n",
      "        (conv): Conv1d(1024, 160, kernel_size=(1,), stride=(1,))\n",
      "        (lstm): LSTM(1664, 1024, num_layers=2)\n",
      "        (attention_lstm): LSTM(80, 1024)\n",
      "        (attention_layer): Attention(\n",
      "          (softmax): Softmax(dim=2)\n",
      "          (query): LinearNorm(\n",
      "            (linear_layer): Linear(in_features=1024, out_features=640, bias=False)\n",
      "          )\n",
      "          (key): LinearNorm(\n",
      "            (linear_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "          )\n",
      "          (value): LinearNorm(\n",
      "            (linear_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "          )\n",
      "          (v): LinearNorm(\n",
      "            (linear_layer): Linear(in_features=640, out_features=1, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_layer): DenseLayer(\n",
      "          (layers): ModuleList(\n",
      "            (0-1): 2 x LinearNorm(\n",
      "              (linear_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (gate_layer): LinearNorm(\n",
      "          (linear_layer): Linear(in_features=1664, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (convolutions): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): ConvNorm(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        )\n",
      "        (1): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\torch\\serialization.py:1101: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\torch\\serialization.py:1101: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\torch\\serialization.py:1101: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Traceback (most recent call last):\n",
      "  File \"inference.py\", line 140, in <module>\n",
      "    infer(args.flowtron_path, args.waveglow_path, args.output_dir, args.text,\n",
      "  File \"inference.py\", line 62, in infer\n",
      "    model.load_state_dict(state_dict.state_dict())\n",
      "  File \"c:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2152, in load_state_dict\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "RuntimeError: Error(s) in loading state_dict for Flowtron:\n",
      "\tsize mismatch for speaker_embedding.weight: copying a param with shape torch.Size([2311, 128]) from checkpoint, the shape in current model is torch.Size([1, 128]).\n"
     ]
    }
   ],
   "source": [
    "# !python inference.py -c pre-trained.json -f \"g:\\outdir\\model_90\" -w \"G:\\\\Research\\\\nvidia_flowtron\\\\waveglow_256channels_ljs_v3.pt\" -t \"It is well know that deep generative models have a rich latent space!\" -i 0\n",
    "!python inference.py -c config.json -f \"G:\\\\Research\\\\nvidia_flowtron\\\\flowtron.pt\" -w \"G:\\\\Research\\\\nvidia_flowtron\\\\waveglow_256channels_ljs_v3.pt\" -t \"It is well know that deep generative models have a rich latent space!\" -i 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'G:\\\\Research\\nvidia_flowtron\\x0clowtron\\results\\\\sid0_sigma0.5.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# show the audio file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mipd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mipd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mResearch\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mvidia_flowtron\u001b[39;49m\u001b[38;5;130;43;01m\\f\u001b[39;49;00m\u001b[38;5;124;43mlowtron\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mesults\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msid0_sigma0.5.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1411\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\IPython\\lib\\display.py:130\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\IPython\\lib\\display.py:152\u001b[0m, in \u001b[0;36mAudio._make_wav\u001b[1;34m(data, rate, normalize)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwave\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_normalize_with_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m Audio\u001b[38;5;241m.\u001b[39m_validate_and_normalize_without_numpy(data, normalize)\n",
      "File \u001b[1;32mc:\\Users\\tibed\\anaconda3\\envs\\flowtron\\lib\\site-packages\\IPython\\lib\\display.py:172\u001b[0m, in \u001b[0;36mAudio._validate_and_normalize_with_numpy\u001b[1;34m(data, normalize)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_normalize_with_numpy\u001b[39m(data, normalize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    174\u001b[0m         nchan \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'G:\\\\Research\\nvidia_flowtron\\x0clowtron\\results\\\\sid0_sigma0.5.wav'"
     ]
    }
   ],
   "source": [
    "# load the wav file and play it\n",
    "from IPython.display import Audio\n",
    "Audio('g:\\outdir\\model_10\\inference.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
